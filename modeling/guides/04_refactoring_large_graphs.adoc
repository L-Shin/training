= Refactoring large graphs
:icons: font

== Refactoring large graphs

In the previous section we noticed that our refactoring queries were slowing down once we'd loaded more flights into the database.

Once the amount of date gets a big larger we'll probably want to execute these refactorings in batches.
Let's look at how we'd do that.

== Refactoring workflow

A typical workflow would be:

* tag all the nodes we need to process with a temporary label e.g. `Process`
* iterate over a subset of nodes flagged with that label (using `LIMIT`) and execute the refactoring
* remove the tag from the node
* return a count of how many rows were processed
* once the count reaches 0 then we've finished.

== Manual batching

We're now sacrificing the atomicity that we'd get if we did everything in one transaction so it makes sense to make our refactoring queries idempotent in case we need to re-run them.
We also need to decide which node we're going to center the refactoring around.

To recap, this was the refactoring query from the previous section:

[source, cypher]
----
MATCH (origin:Airport)<-[:ORIGIN]-(flight:Flight)-[:DESTINATION]->(destination:Airport)

MERGE (originAirportDay:AirportDay {id: origin.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
ON CREATE SET originAirportDay.date = flight.date

MERGE (destinationAirportDay:AirportDay {id: destination.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
ON CREATE SET destinationAirportDay.date = flight.date

MERGE (origin)-[:HAS_DAY]->(originAirportDay)
MERGE (flight)-[:ORIGIN]->(originAirportDay)
MERGE (flight)-[:DESTINATION]-(destinationAirportDay)
----

`Flight` is probably the easiest node to batch on.

Before we execute the batching workflow, let's import a few more flights to keep it interesting.

== Importing 500,000 flights

As we're now dealing with much more data we'll have to be a bit cleverer about how we import the data.

We know that most of the airports are going to be duplicates so there's no point calling `MERGE` loads of times.
Instead we'll find the distinct set of airports and only `MERGE` on each airport once:

[source, cypher, subs=attributes]
----
LOAD CSV WITH HEADERS FROM "{csv-url}_500k.csv" AS row
UNWIND [row.Origin, row.Dest] AS airport
WITH DISTINCT airport
MERGE (:Airport {code: airport})
----

We'll also use the periodic commit functionality of `LOAD CSV`.
This will flush the transaction every 10,000 rows rather than executing the whole query in one transaction.

[source, cypher, subs=attributes]
----
USING PERIODIC COMMIT 10000
LOAD CSV WITH HEADERS FROM "{csv-url}flights_500k.csv" AS row
MATCH (origin:Airport {code: row.Origin})
MATCH (destination:Airport {code: row.Dest})
MERGE (newFlight:Flight { id: row.UniqueCarrier + row.FlightNum + "_" + row.Year + "-" + row.Month + "-" + row.DayofMonth + "_" + row.Origin + "_" + row.Dest }   )
ON CREATE SET newFlight.date = TOINT(row.Year) + "-" + TOINT(row.Month) + "-" + TOINT(row.DayofMonth),
              newFlight.airline = row.UniqueCarrier,
              newFlight.number = row.FlightNum,
              newFlight.departure = row.Dest,
              newFlight.arrival = row.UniqueCarrier
MERGE (origin)<-[:ORIGIN]-(newFlight)
MERGE (newFlight)-[:DESTINATION]->(destination)
----

Now we're ready to do some batch refactoring.

== Batch refactoring flights

Let's put a `Process` label on each of our `Flight` nodes so that we know which ones we've still got to process.

[source, cypher]
----
MATCH (f:Flight)
SET f:Process
----

Now we're ready to run the refactoring query.
We'll start by processing 500 flights at a time:

[source, cypher]
----
MATCH (flight:Process)
WITH flight LIMIT 500

MATCH (origin:Airport)<-[:ORIGIN]-(flight)-[:DESTINATION]->(destination:Airport)

MERGE (originAirportDay:AirportDay {id: origin.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
ON CREATE SET originAirportDay.date = flight.year + "-" + flight.month + "-" + flight.day

MERGE (destinationAirportDay:AirportDay {id: destination.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
ON CREATE SET destinationAirportDay.date = flight.year + "-" + flight.month + "-" + flight.day

MERGE (origin)-[:HAS_DAY]->(originAirportDay)
MERGE (originAirportDay)<-[:ORIGIN]-(flight)
MERGE (flight)-[:DESTINATION]-(destinationAirportDay)

REMOVE flight:Process
RETURN COUNT(*)
----

We'd have to run this query 500,000 / 500 = 1,000 times to process all the flights, which would be a very boring way to pass the time!

Lucky for us, Neo4j 3.0 saw the introduction of procedures which can significantly simplify things.

== Procedures

Procedures allow us to write custom code in any JVM language, wrap it up in a function, and call it from Cypher.

The Neo4j community has built a collection of over 200 procedures in the Awesome Procedures (`apoc`) package over the last 6 months.
Hopefully we'll find one which can help us out with our batch refactoring efforts.

But first let's get `apoc` setup on your machines:

pass:a[<a play-topic='{guides}/installing_apoc.html'>Awesome Procedures</a>]

== Exploring `apoc`

Spend a bit of time looking through the collection of procedures that `apoc` provides.

Can you work out which procedure we need to automate batch refactoring?

_Hint_ The link:https://neo4j-contrib.github.io/neo4j-apoc-procedures/[user guide] will probably come in handy.

== Batch refactoring with `apoc`

The following procedure is the one we want:

[source, cypher]
----
CALL apoc.help("apoc.periodic.commit")
----

We can also pass the `apoc.help` procedure a package name and it'll show us all the procedures in that package.
e.g.

[source, cypher]
----
CALL apoc.help("apoc.periodic")
----

Let's get on with the batch refactoring.

== Batch refactoring with `apoc`

Since we've imported more nodes we'll need to tag them with the `Process` label.
For simplicity's sake we'll just put the `Process` tag on all our flights and process them all again.

[source, cypher]
----
MATCH (f:Flight)
SET f:Process
----

_Hint_ Remember, since our query is idempotent, if a flight has already been processed before the query won't actually do anything with that flight.

We can now call our refactoring query inside the procedure:

[source,cypher]
----
call apoc.periodic.commit('
  MATCH (flight:Process)
  WITH flight LIMIT {limit}

  MATCH (origin:Airport)<-[:ORIGIN]-(flight)-[:DESTINATION]->(destination:Airport)

  MERGE (originAirportDay:AirportDay {id: origin.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
  ON CREATE SET originAirportDay.date = flight.year + "-" + flight.month + "-" + flight.day

  MERGE (destinationAirportDay:AirportDay {id: destination.code + "_" + flight.year + "-" + flight.month + "-" + flight.day})
  ON CREATE SET destinationAirportDay.date = flight.year + "-" + flight.month + "-" + flight.day

  MERGE (origin)-[:HAS_DAY]->(originAirportDay)
  MERGE (originAirportDay)<-[:ORIGIN]-(flight)
  MERGE (flight)-[:DESTINATION]-(destinationAirportDay)

  REMOVE flight:Process
  RETURN COUNT(*)
',{limit:500})
----

==

== Next

In the next section we're going to spend some time looking at specific relationship types.

pass:a[<a play-topic='{guides}/05_specific_relationship_types.html'>Specific Relationship Types</a>]
